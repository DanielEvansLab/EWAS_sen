---
title: "EWAS senescence"
author: "Dan Evans"
output: 
  BiocStyle::html_document:
    toc_float: true
    toc_depth: 3
    fig_caption: yes

fontsize: 14 pt

vignette: >
  %\VignetteIndexEntry{EWAS senescence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

# EWAS introduction

DNA methylation quantity is expressed as $\beta$ 

$$ \beta = M/(M + U)  $$

Where M = hybridization signal from a methylated version of a cytosine nucleotide and 
U =  hybridization signal from an unmethylated version of a cytosine nucleotide. Beta can be interpreted as the proportion of methylation signal for a probe, and values range from 0 to 1. Beta is easy to interpret for humans, but typically has a bimodal distribution that is suboptimal for statistical modeling. Thus, we analyze M-values, which are another way to express methylation values for probes. 

$$ M-value = log_2(M/U) $$

EPIC array has type 1 and type 2 probes. Type 1 probes are from the old 27K array that uses 2 bead types per CpG. The type I probes are labeled I-green and I-red. The newer type 2 probes uses one bead type. Most of the EPIC array probes are type II.  

A detection probability represents the probability of a detected signal being background flourescence. If the probability is high, the signal is more likely to be background, and the value should be set to missing.

Standard workflows suggest to remove data points with detection P-value > 0.05.  

# Sesame package processing of Illumina EPIC array

## Sesame package intro

- EWAS array Illumina EPIC 850 

- Sesame is a [bioconductor package](https://www.bioconductor.org/packages/release/bioc/html/sesame.html)
  + Improvements on previous EWAS packages for low-level processing. 
  + Existing methods do not identify artifacts associated with detection failure. Sources of failure include: insufficient DNA due to germline or somatic deletions or hyperpolymorphism, probe cross-hybridization. 
  + Probes are masked (set to NA) with two methods: P-value with out-of-band array hybridization (pOOBAH) so that probes with detection p-value > 0.05 are masked. Probes with design issues such as overlapping SNPs are masked. Minfi uses negative control probes for background, but there are only 411 of them on the EPIC array. Sesame pOOBAH uses out-of-band (OOB) signals from type I probes in addition to negative control probes to improve background subtraction and detection calling. Minfi adopted pOOBAH, but false positive rate higher than Sesame's implementation (Fig 2 Zhou 2018, NAR).  
  + Non-linear dye bias correction. Minfi uses linear scaling. Sesame uses nonlinear scaling to better fit dye bias. 

```{r, setup}
knitr::opts_chunk$set(cache.lazy = FALSE)
```

## Sesame installation on UCR cluster

Installation of sesame and dependencies went fine, no errors or warnings.

```{r, eval = FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("sesame", lib = "~/Rlibs")
```

Installed sesameData as a dependency. 

Can check version of loaded packages with sessionInfo()

Sesame version 1.6 used.

## Load libraries

This includes libraries for Sesame and Minfi.

```{r message = FALSE}
library(tidyverse)
library(readxl)
library(knitr)
library(sesame)
library(wheatmap)
library(multtest)
library(limma)
library(RColorBrewer)
library(minfi)
library(IlluminaHumanMethylationEPICmanifest)
library(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)
```

Set global variables.

```{r}

dir_out <- "../results/"


```

## Mask and normalize data and create eset

Sesame pipeline involves probe masking with pOOBAH, normalization with noob, and nonlinear dye bias correction.

Noob = background subtraction based on normal-exponential deconvolution using out-of-band probes.

The pipeline can be thought of as adding pOOBAH to noob. Then also the non-linear dye bias correction should be better than minfi's linear correction. 

OpenSesame takes 12 minutes, so run it once and save the output.

```{r, cache = TRUE, message = FALSE, warning = FALSE}

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/idatFiles/")
t1 <- Sys.time()
betas <- openSesame(IDATprefixes)
Sys.time() - t1
#Warnings issued. These are also shown in minfi vignette, so they are expected. 
#50: In readChar(con, nchars = n) : truncating string with embedded nuls

#Convert Betas to Mvalues. Check if there are beta values that will result in infinite results.
sum(is.na(betas))
sum(is.na(betas))/length(betas)
sum(betas==0 & !is.na(betas))
sum(betas==1 & !is.na(betas))
sum(betas<0 & !is.na(betas))
sum(betas>1 & !is.na(betas))

Mvals <- BetaValueToMValue(betas)

#column names for betas and Mvals is currently the Basename. Rename it to sampleID to make it easier to understand.
sampsheet <- read_csv("../data/raw/idatFiles/SampleSheet.csv")
#Are there true discrepancies between ExternalSampleID, SampleLabel, and Description?
#row 2 ExternalSampleID shows "+P" but SampleLabel shows "-P" and Description shows "no pyruvate". Many discrepancies like that. I ended up trusting SampleLabel and Description, but is that wrong? 
cbind(sampsheet$ExternalSampleID, sampsheet$SampleLabel, sampsheet$Description)
sum(colnames(betas) != sampsheet$Basename) #not in same order
cbind(colnames(betas),sampsheet$Basename) #visually show not in same order
cbind(colnames(betas),sampsheet$Basename[match(sampsheet$Basename, colnames(betas))])#now in correct order
#reorder sampsheet to match sample order in data matrix
sampsheet <- sampsheet[match(sampsheet$Basename, colnames(betas)),]
sampsheet <- dplyr::rename(sampsheet, sampleID = ExternalSampleID)
cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description)
sampsheet$sampleID[1:8] <- paste0("ATV", 1:8)
sampsheet$sampleID[9:32] <- paste0("midas", 1:24) 
cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description)

translate_trt <- function(ch){
  switch(ch,
	 "Non-senescent DMSO-treated control cells" = "noSen_ATV",
	 "Non-senescent mtDNA-containing controls no pyruvate" = "noSen_Mt_noPy", 
	 "Non-senescent mtDNA-containing controls with pyruvate" = "noSen_Mt_Py",
	 "Non-senescent mtDNA-depleted controls cells with pyruvate" = "noSen_noMt_Py",
	 "Senescent ATV-treated cells" = "sen_ATV",
	 "Senescent mtDNA-depleted cells no pyruvate" = "sen_noMt_noPy"
	 )
}

sampsheet <- sampsheet %>%
	mutate(treatment = map_chr(Description, translate_trt)) %>%
	mutate(treatment = factor(treatment))

cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description, as.character(sampsheet$treatment))

colnames(betas) <- sampsheet$sampleID
colnames(Mvals) <- sampsheet$sampleID 
row.names(sampsheet) <- sampsheet$sampleID

#Probe annotation
dat_fData <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
length(rownames(betas)) == length(dat_fData$probeID)
sum(rownames(betas) != dat_fData$probeID)
#Reorder annotation to match betas
dat_fData <- dat_fData[match(rownames(betas), dat_fData$probeID),]
sum(rownames(betas) != dat_fData$probeID)
head(dat_fData$probeID)
head(rownames(betas))
row.names(dat_fData) <- dat_fData$probeID

eset_betas <- ExpressionSet(assayData = betas,
			    phenoData = AnnotatedDataFrame(sampsheet),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

write_rds(eset_betas, path = "../data/formatted/eset_betas.rds")

eset_Mvals <- ExpressionSet(assayData = Mvals,
			    phenoData = AnnotatedDataFrame(sampsheet),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

write_rds(eset_Mvals, path = "../data/formatted/eset_Mvals.rds")
```

## QC on IDATs

The sesame pipeline above already produced cleaned data. This chunk goes backwards and examines QC of the raw data again.

Read in idats as sigsets, apply QC.

The Sigset data structure is an S4 class with 6 slots. Using lapply with readIDATpair creates a list of Sigset objects. Each list element is a Sigset for each sample. To plot or anything across samples, you'll need to apply a function across the list.

```{r, cache = TRUE, message = FALSE, warning = FALSE}
pdat <- pData(eset_Mvals)
IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/idatFiles/")
ssets <- lapply(IDATprefixes, readIDATpair)
qc10 <- do.call(rbind, lapply(ssets, function(x) as.data.frame(sesameQC(x))))
#add sample names
sum(names(ssets) != pdat$Basename)
cbind(names(ssets), pdat$Basename)
qc10 <- qc10 %>%
	mutate(sample_name = pdat$SampleLabel) %>%
	mutate(sample_desc = pdat$Description) %>%
	dplyr::select(sample_name, sample_desc, everything())

#frac_na_cg = percentage of cg probes with NA
#mean_intensity = for type II probes. Low intensity typically bad quality
#mean_beta_cg = mean beta cg probes
#frac_meth_cg = percentage cg probes with beta > 0.7
#frac_unmeth_cg = percentage cg probes with beta < 0.3
#GCT = residual incomplete bisulfite conversion. Closer to one = more complete conversion.
qcvars <- c("sample_name", "sample_desc", "num_probes_cg", "num_na_cg", "frac_na_cg", "mean_intensity", "mean_beta_cg", "frac_meth_cg", "frac_unmeth_cg", "sex", "age", "ethnicity", "GCT")
qc10 %>%
	dplyr::select(any_of(qcvars)) %>%
	kable

```


## Missing analysis of masked Betas

The fraction of NAs are signs of masking due to variety of reasons including failed detection, high background, putative low quality probes etc. 

Now we move back to the QCed betas generated from the first step. 

First, remove failed samples and probes. How many samples are missing across all probes? How many probes are missing across all samples? 

```{r, cache = TRUE}
dim(eset_Mvals) #865,918 probes
e <- exprs(eset_Mvals)
pdat <- pData(eset_Mvals)
miss_sample <- apply(e, 2, function(x) sum(is.na(x))/length(x) )
miss_probe_blank <- apply(e, 1, function(x) sum(is.na(x))/length(x) )
length(miss_sample)
length(miss_probe_blank)
sum(miss_sample >= 0.95) #0 samples have missing rate greater than 95% 
#no samples that are essentially blanks.
#show missingness for all samples
data.frame(sampleID = names(miss_sample), treatment = pdat$treatment, miss_sample = miss_sample, stringsAsFactors = F) %>%
  kable()

sum(miss_probe_blank >= 1) #119,631 completely missing probes. Many are masked by design.
sum(miss_probe_blank >= 0.95) #121,925 Remove these, then determine number of samples with missing rate>0.05.

#keep probes with < 0.95 missingness
eset_Mvals_clean <- eset_Mvals[miss_probe_blank < 0.95,]
dim(eset_Mvals_clean) #743,993 probes
eset_betas_clean <- eset_betas[miss_probe_blank < 0.95,]
dim(eset_betas_clean)

#After removing failed probes, estimate sample missing rate.
e <- exprs(eset_Mvals_clean)
miss_sample <- apply(e, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(e, 1, function(x) sum(is.na(x))/length(x) )

data.frame(sampleID = names(miss_sample), treatment = pdat$treatment, miss_sample = miss_sample, stringsAsFactors = F) %>%
  kable()

#After removing failed probes, estimate probe missing rate

sum(miss_probe == 0) #692,879 probes with no missings
sum(miss_probe > 0) #51,114 probes with missings in at least one sample
miss_probe_f <- cut(miss_probe, breaks = seq(0, 1, 0.1))
table(miss_probe_f)

data.frame(missing_interval = miss_probe_f) %>%
	filter(!is.na(missing_interval)) %>%
	ggplot(aes(missing_interval)) + 
	  geom_bar()

```

## Distributions

Summary of sample IDs and descriptions

```{r cache = TRUE}
p1 <- pData(eset_Mvals_clean)
p1 %>%
	dplyr::select(sampleID, Description) %>%
	kable()
```

### Boxplots of M-values

```{r cache = TRUE}
boxplot(exprs(eset_Mvals_clean), las = 2, ylab = "M-values")
abline(h = median(exprs(eset_Mvals_clean)), col = "blue")

```

### Density plot All samples combined

```{r cache = TRUE}
plotDensities(eset_betas_clean, main = "Betas", legend = FALSE)

plotDensities(eset_Mvals_clean, main = "M values", legend = FALSE)

```

### Density plot sample groups

```{r cache = TRUE}
p1 <- pData(eset_Mvals_clean)
p1 %>%
	dplyr::select(sampleID, SampleLabel, Description, treatment) %>%
	kable()

eset_Mvals_sub <- eset_Mvals_clean[,which(p1$treatment == "senATV" | p1$treatment == "noSen_ATV")]
plotDensities(eset_Mvals_sub, main = "M values ATV", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[,which(p1$treatment == "sen_noMt_noPy"  | p1$treatment == "noSen_noMt_Py" | p1$treatment == "noSen_Mt_noPy" | p1$treatment == "noSen_Mt_Py")]
plotDensities(eset_Mvals_sub, main = "M values MiDAS sen and controls", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[,which(p1$treatment == "sen_noMt_noPy")]
plotDensities(eset_Mvals_sub, main = "M values MiDAS sen", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[,which(p1$treatment == "noSen_noMt_Py" | p1$treatment == "noSen_Mt_noPy" | p1$treatment == "noSen_Mt_Py")]
plotDensities(eset_Mvals_sub, main = "M values MiDAS controls", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[,which(p1$treatment == "noSen_noMt_Py")]
plotDensities(eset_Mvals_sub, main = "M values MiDAS controls no MT Py", legend = TRUE)
```

## PCA
```{r cache = TRUE}
plot_MDS <- function(mylabel, myeset){
	group <- pData(myeset)[[mylabel]]
	col.group <- group
	levels(col.group) <- brewer.pal(nlevels(col.group), "Dark2")
	col.group.ch <- as.character(col.group)
	plotMDS(myeset, col = col.group.ch, gene.selection = "common", main = paste(mylabel, "labels"), pch = 16)
	legend("topleft", fill = levels(col.group), legend = levels(group))
}

plot_MDS(mylabel = "treatment", myeset = eset_betas_clean)
plot_MDS(mylabel = "treatment", myeset = eset_Mvals_clean)


```

## PCA ATV samples
```{r cache = TRUE}
plot_MDS <- function(mylabel, myeset){
	group <- pData(myeset)[[mylabel]]
	col.group <- group
	levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
	col.group.ch <- as.character(col.group)
	plotMDS(myeset, col = col.group.ch, gene.selection = "common", main = paste(mylabel, "labels"), pch = 16)
	legend("top", fill = levels(col.group), legend = levels(group))
}

keep <- str_detect(pData(eset_Mvals_clean)$sampleID, "ATV")
eset_sub <- eset_Mvals_clean[, keep]
plot_MDS(mylabel = "treatment", myeset = eset_sub)


```

## Identify PCA outliers

```{r cache = TRUE}
myMDS <- plotMDS(eset_Mvals_clean, gene.selection = "common", plot = FALSE)
cluster_top <- myMDS$y[myMDS$y > 0.2 ]
cluster_bottom <- myMDS$x[myMDS$x > 1 ]
cluster_ATV <- myMDS$x[myMDS$x < (-2) ]

#cluster top
pData(eset_Mvals_clean) %>%
	filter(sampleID %in% names(cluster_top)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable

#cluster bottom
pData(eset_Mvals_clean) %>%
	filter(sampleID %in% names(cluster_bottom)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable

#cluster ATV
pData(eset_Mvals_clean) %>%
	filter(sampleID %in% names(cluster_ATV)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable
```

## Density plots of PCA clusters

```{r cache = TRUE}
plotDensities(eset_Mvals_clean, main = "M values all samples", legend = FALSE)

p1 <- pData(eset_Mvals_clean)
p1 %>%
	dplyr::select(sampleID, SampleLabel, Description, treatment) %>%
	kable()
eset_Mvals_sub <- eset_Mvals_clean[, p1$sampleID %in% names(cluster_top)]
plotDensities(eset_Mvals_sub, main = "M values cluster top", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[, p1$sampleID %in% names(cluster_bottom)]
plotDensities(eset_Mvals_sub, main = "M values cluster bottom", legend = TRUE)

eset_Mvals_sub <- eset_Mvals_clean[, p1$sampleID %in% names(cluster_ATV)]
plotDensities(eset_Mvals_sub, main = "M values cluster ATV", legend = TRUE)

```

## Probe-wise analysis of senescence treatment

### Model parameterization

Group means parameterization. No intercept. 

$$ Y = B_1X_1 + B_2X_2 + B_3X_3 + B_4X_4 + B_5X_5 + B_6X_6 + \epsilon $$

$B_1$ = mean expression level in noSen_ATV. 

$B_2$ = mean expression level in noSen_Mt_Py. 

$B_3$ = mean expression level in noSen_Mt_noPy. 

$B_4$ = mean expression level in noSen_noMt_Py.

$B_5$ = mean expression level in sen_ATV.

$B_6$ = mean expression level in sen_noMt_noPy.

After model fit, contrasts are set that represent difference in group means.

logFC = estimate of the log2-fold-change

CI.L = lower 95% confidence interval for logFC

CI.R = upper 95% confidence interval for logFC

AveExpr = average log2-expression for the probe over all samples

t = moderated t-statistic

P.value = unadjusted P-value

adj.P.value = BH 1995 adjusted P-value

B = log-odds that the variable is differentially abundant. 

From the limma user guide: Suppose for example that B = 1.5. The odds of differential expression is exp(1.5)=4.48, i.e, about four and a half to one. The probability that the gene is differentially expressed is 4.48/(1+4.48)=0.82, i.e., the probability is about 82% that this gene is differentially expressed. A B-statistic of zero corresponds to a 50-50 chance that the gene is differentially expressed. The B-statistic is automatically adjusted for multiple testing by assuming that 1% of the genes are expected to be differentially expressed. The p-values and B-statistics will normally rank genes in the same order. 



```{r, cache = TRUE}

design <- model.matrix(~0 + treatment, data = pData(eset_Mvals_clean))
design
colSums(design)

cm <- makeContrasts(ATVvControl = treatmentsen_ATV - treatmentnoSen_ATV,
		    SenMidasvNoSenMtnoPy = treatmentsen_noMt_noPy - treatmentnoSen_Mt_noPy,
		    SenMidasvNoSenNoMtPy = treatmentsen_noMt_noPy - treatmentnoSen_noMt_Py,
		    levels = design
		    )
fit <- lmFit(eset_Mvals_clean, design)
fit2 <- contrasts.fit(fit, contrasts = cm)
fit2 <- eBayes(fit2)

results <- decideTests(fit2)
summary(results)
vennDiagram(results)

volcanoplot(fit2, coef = "ATVvControl" , main = "ATV vs control")
volcanoplot(fit2, coef = "SenMidasvNoSenMtnoPy", main = "MiDAS vs control with MtDNA")
volcanoplot(fit2, coef = "SenMidasvNoSenNoMtPy", main = "MiDAS vs control without mtDNA")

annot_cols <- c("CpG_chrm", "CpG_beg", "probeID", "gene")
topTable(fit2, coef = "ATVvControl", genelist = fit2$genes[,annot_cols], p.value = 0.05, confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenMtnoPy", genelist = fit2$genes[,annot_cols], p.value = 0.05, confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenNoMtPy", genelist = fit2$genes[,annot_cols], p.value = 0.05, confint = TRUE) %>%
	kable()

#save results 
resultAll <- topTable(fit2, coef = "ATVvControl", sort.by = "none", number = nrow(fit2), confint = TRUE)
write_csv(resultAll, path = paste0(dir_out, "ATVvControl.csv"))
resultAll <- topTable(fit2, coef = "SenMidasvNoSenMtnoPy", sort.by = "none", number = nrow(fit2), confint = TRUE)
write_csv(resultAll, path = paste0(dir_out, "SenMidasvNoSenMtnoPy.csv"))
resultAll <- topTable(fit2, coef = "SenMidasvNoSenNoMtPy", sort.by = "none", number = nrow(fit2), confint = TRUE)
write_csv(resultAll, path = paste0(dir_out, "SenMidasvNoSenNoMtPy.csv"))


```

### Compare old ATV results with sesame results

Array annotation downloaded [here](http://zwdzwd.github.io/InfiniumAnnotation#current).

Old results are my quick t-tests performed on Nate's Noob-normalized data using minfi. I saw lots of significant ATV associations in old results, but not from the sesame-based results. What are the differences? 

There are many differences between old and new ATV results. Differences include:

1. Preprocessing. Old results from minfi noob preprocessing. New results from sesame noob and pOOBAH.

2. Methylation values. Old results calculated from Betas. New results calculated from M-values.

3. Association testing. Old results calculated from t-test. New results calculated from moderated t-tests using limma. Limma should have more power, and should be more robust because variance won't be influenced by probes with high variance.

Results below show there are many differences between old results and new Sesame with limma. 

```{r message = FALSE, cache = TRUE}

fdat <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
dat <- read_csv(paste0(dir_out, "ATVvControl.csv"))
datOld <- read_csv(paste0(dir_out, "probewise_ATV.csv"))

datOld %>%
	filter(P_BH <= 0.05) %>%
	left_join(fdat, by = "probeID") %>%
	summarize(n_masked = sum(MASK_general), n_not_masked = sum(!MASK_general))

names(datOld)[2:4] <- paste("v1", names(datOld)[2:4], sep = "_")
datOld %>%
	filter(v1_P_BH <= 0.05) %>%
	left_join(dat, by = "probeID") %>%
	select(probeID, v1_T_STAT, v1_P, v1_P_BH, t, P.Value, adj.P.Val, everything()) %>%
	arrange(v1_P) %>%
	slice_head(n = 10)

datMerge <- inner_join(datOld, dat, by = "probeID") 
cor1 <- cor(datMerge$v1_T_STAT, datMerge$t, use = "complete.obs")
if(cor1 < 0.1) cor1 <- 0.1

datOld %>%
	inner_join(dat, by = "probeID") %>%
	filter(!is.na(v1_T_STAT)) %>%
	filter(!is.na(t)) %>%
	ggplot(aes(x = v1_T_STAT, y = t)) +
	geom_hex(binwidth = c(cor1, cor1)) +
	labs(x = "old results (minfi noob t-test)", 
	     y = "new results",
	     caption = "Old results are from Nate minfi noob data with Dan t-test."
	     )

```
# Minfi processing

Since the sesame-based results are so different from the noob-normalized minfi results, let me try minfi noob myself, with some additional QC steps. Besides, the minfi noob results had many significant associations. 

## Replicate old results from Nate's data

This code chunk creates a noob processed dataset from the raw data. Should be the same as data from Nate.

Output is a matrix of betas. Then, apply unpaired t-test and compare to my previous results. Results should replicate, as long as my minfi noob preprocess was the same as Nate's. 

Summary methods:
Minfi noob
Beta values
Unpaired t-test

If I can replicate results, then I start adding different layers to see if significant associations can be retained while still performing robust QC.

```{r cache = TRUE, message = FALSE, warning = FALSE}

baseDir <- "../data/raw/idatFiles/"
targets <- read.csv(paste0(baseDir, "SampleSheet.csv"))
targets$BasenameOriginal <- as.character(targets$Basename)
targets$Slide <- substr(targets$Basename, 1, 12)
targets$Basename <- paste0(baseDir, targets$Slide, "/", targets$BasenameOriginal)

rgSet <- read.metharray.exp(base = NULL, targets = targets, recursive = TRUE, force = TRUE)

#must load manifest to perform preprocessNoob
Mset <- preprocessNoob(rgSet)
gset <- mapToGenome(Mset)
grset <- ratioConvert(gset, what = "both")
beta_n <- getBeta(grset)
ewas <- data.frame(ID = row.names(beta_n), beta_n)
names(ewas) <- str_replace_all(names(ewas), pattern = "^X", replacement = "")
names(ewas)[1] <- "probeID"

#Targets and sample IDs in same order
sum(names(ewas)[-1] != targets$BasenameOriginal)
cbind(names(ewas)[-1], targets$BasenameOriginal)

#create new variables in sample sheet to indicate contrasts
samp <- targets %>%
	mutate(ATV = ifelse(str_detect(ExternalSampleID, "\\+ ATV"), 1L, 0L))
samp$ATV[str_detect(samp$ExternalSampleID, ".*ATV.*", negate = TRUE)] <- NA
cbind(samp$ATV, samp$ExternalSampleID)

betaMat <- ewas %>%
	dplyr::select(-probeID) %>%
	as.matrix

# Association testing
lm_fun <- function(cg){
  out <- tryCatch({
    lm1 <- t.test(cg ~ ATV, data = samp, na.action = na.omit)
    tstat <- lm1$statistic
    p <- lm1$p.value
    return(c(tstat, p))
  
  }, error = function(e) rep(NA, 2)
		  )
}


results <- apply(betaMat, 1, lm_fun)
results <- t(results)
colnames(results) <- c("T_STAT", "P")
resultsTB <- as_tibble(results)
resultsTB <- resultsTB %>%
	mutate(probeID = row.names(results)) %>%
	dplyr::select(probeID, everything())
adjp1 <- mt.rawp2adjp(resultsTB[["P"]], proc = "BH")
resultsTB <- resultsTB %>%
	mutate(P_BH = adjp1$adjp[order(adjp1$index), "BH"])

sum(resultsTB$P_BH <= 0.05)

#Are new results the same as the old results from data from Nate?
datOld <- read_csv("../results/probewise_ATV.csv")
sum(datOld$P_BH <= 0.05)

names(datOld)[2:4] <- paste("v1", names(datOld)[2:4], sep = "_")
datOld %>%
	filter(v1_P_BH <= 0.05) %>%
	left_join(resultsTB, by = "probeID") %>%
	arrange(v1_P) %>%
        slice_head(n = 10) %>%
	kable(digits = 9)

datOld %>%
	inner_join(resultsTB, by = "probeID") %>%
	filter(!is.na(v1_T_STAT)) %>%
	filter(!is.na(T_STAT)) %>%
	ggplot(aes(x = v1_T_STAT, y = T_STAT)) +
	geom_bin2d(binwidth = c(0.8, 0.8)) +
	labs(x = "old results (Nate minfi noob t-test)", 
	     y = "new results (Dan minfi noob t-test)",
	     caption = "Old results are from Nate minfi noob data with Dan t-test. New results are from Dan minfi noob data with Dan t-test."
	     )

```

# Minfi noob normalization and limma

Now that I can replicate my old results, let's see if simply adding limma on top removes all of the significant findings.

Summary methods:
Minfi noob
Beta values
Limma


```{r cache = TRUE, message = FALSE, warning = FALSE}
baseDir <- "../data/raw/idatFiles/"
targets <- read.csv(paste0(baseDir, "SampleSheet.csv"))
targets$BasenameOriginal <- as.character(targets$Basename)
targets$Slide <- substr(targets$Basename, 1, 12)
targets$Basename <- paste0(baseDir, targets$Slide, "/", targets$BasenameOriginal)

rgSet <- read.metharray.exp(base = NULL, targets = targets, recursive = TRUE, force = TRUE)

#must load manifest to perform preprocessNoob
Mset <- preprocessNoob(rgSet)
gset <- mapToGenome(Mset)
grset <- ratioConvert(gset, what = "both")
bVals <- getBeta(grset)

#Targets and sample IDs in same order
sum(names(bVals) != targets$BasenameOriginal)
cbind(names(bVals), targets$BasenameOriginal)

#create new variables in sample sheet to indicate contrasts
translate_trt <- function(ch){
  switch(ch,
	 "Non-senescent DMSO-treated control cells" = "noSen_ATV",
	 "Non-senescent mtDNA-containing controls no pyruvate" = "noSen_Mt_noPy", 
	 "Non-senescent mtDNA-containing controls with pyruvate" = "noSen_Mt_Py",
	 "Non-senescent mtDNA-depleted controls cells with pyruvate" = "noSen_noMt_Py",
	 "Senescent ATV-treated cells" = "sen_ATV",
	 "Senescent mtDNA-depleted cells no pyruvate" = "sen_noMt_noPy"
	 )
}

targets <- targets %>%
	mutate(treatment = map_chr(Description, translate_trt)) %>%
	mutate(treatment = factor(treatment))

design <- model.matrix(~0 + treatment, data = targets)
design
colSums(design)

cm <- makeContrasts(ATVvControl = treatmentsen_ATV - treatmentnoSen_ATV,
		    SenMidasvNoSenMtnoPy = treatmentsen_noMt_noPy - treatmentnoSen_Mt_noPy,
		    SenMidasvNoSenNoMtPy = treatmentsen_noMt_noPy - treatmentnoSen_noMt_Py,
		    levels = design
		    )
fit <- lmFit(bVals, design)
fit2 <- contrasts.fit(fit, contrasts = cm)
fit2 <- eBayes(fit2)

results <- decideTests(fit2)
summary(results)
vennDiagram(results)

volcanoplot(fit2, coef = "ATVvControl" , main = "ATV vs control")
volcanoplot(fit2, coef = "SenMidasvNoSenMtnoPy", main = "MiDAS vs control with MtDNA")
volcanoplot(fit2, coef = "SenMidasvNoSenNoMtPy", main = "MiDAS vs control without mtDNA")

dat <- topTable(fit2, coef = "ATVvControl", n = Inf)
dat <- dat %>%
	mutate(probeID = row.names(dat))
topTable(fit2, coef = "ATVvControl", confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenMtnoPy", confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenNoMtPy", confint = TRUE) %>%
	kable()

#Compare old and new ATV results
datOld <- read_csv(paste0(dir_out, "probewise_ATV.csv"))
names(datOld)[2:4] <- paste("v1", names(datOld)[2:4], sep = "_")
datOld %>%
	filter(v1_P_BH <= 0.05) %>%
	left_join(dat, by = "probeID") %>%
	dplyr::select(probeID, v1_T_STAT, v1_P, v1_P_BH, t, P.Value, adj.P.Val, everything()) %>%
	arrange(v1_P) %>%
	slice_head(n = 10)

datMerge <- inner_join(datOld, dat, by = "probeID") 
cor1 <- cor(datMerge$v1_T_STAT, datMerge$t, use = "complete.obs")
if(cor1 < 0.1) cor1 <- 0.1

datOld %>%
	inner_join(dat, by = "probeID") %>%
	filter(!is.na(v1_T_STAT)) %>%
	filter(!is.na(t)) %>%
	ggplot(aes(x = v1_T_STAT, y = t)) +
	geom_hex(binwidth = c(cor1, cor1)) +
	labs(x = "old results (minfi noob t-test)", 
	     y = "new results (minfi noob, beta values, limma)",
	     caption = "Old results are from Nate minfi noob data with Dan t-test. New results are from minfi noob generating beta values that are analyzed with limma"
	     )

```

# Minfi QC, noob, Mvals and limma for association testing

Minfi noob normalized data with unpaired t-test replicates the old results. However, adding limma made the results totally different. What do we trust? Limma is more trustworthy, especially for small sample sizes. The test-statistics for the vanilla t-tests were way too high (39!) to be believed, which is most likely due to unstable variance estimates. Limma takes care of this, so we should move forward with limma. 

Limma analysis of beta values still retained significant findings for ATV contrast. Now, what about using M-values with basic minfi noob and limma? 

So, this will be the official analysis using minfi processing with additional QC, using Mvalues and limma for association testing.

Create an RGChannelSet object. 

Detection P-values. Set to missing. Remove bad samples and probes. 

Small detection p-values = good signals.

Detection P-value > 0.05 = bad signal. Set to missing. 

## Minfi data import 

```{r cache=TRUE, warning = FALSE, message = FALSE}
baseDir <- "../data/raw/idatFiles/"
targets <- read.csv(paste0(baseDir, "SampleSheet.csv"))
targets$BasenameOriginal <- as.character(targets$Basename)
targets$Slide <- substr(targets$Basename, 1, 12)
targets$Basename <- paste0(baseDir, targets$Slide, "/", targets$BasenameOriginal)

rgSet <- read.metharray.exp(base = NULL, targets = targets, recursive = TRUE, force = TRUE)

#Add nicer sample IDs
sum(colnames(rgSet) != targets$BasenameOriginal)
cbind(colnames(rgSet), targets$BasenameOriginal)
cbind(targets$ExternalSampleID, targets$Description)
targets$sampleID <- ""
targets$sampleID[1:24] <- paste0("midas", 1:24)
targets$sampleID[25:32] <- paste0("ATV", 1:8)

translate_trt <- function(ch){
  switch(ch,
	 "Non-senescent DMSO-treated control cells" = "noSen_ATV",
	 "Non-senescent mtDNA-containing controls no pyruvate" = "noSen_Mt_noPy", 
	 "Non-senescent mtDNA-containing controls with pyruvate" = "noSen_Mt_Py",
	 "Non-senescent mtDNA-depleted controls cells with pyruvate" = "noSen_noMt_Py",
	 "Senescent ATV-treated cells" = "sen_ATV",
	 "Senescent mtDNA-depleted cells no pyruvate" = "sen_noMt_noPy"
	 )
}

targets <- targets %>%
	mutate(treatment = map_chr(Description, translate_trt)) %>%
	mutate(treatment = factor(treatment))

cbind(targets$sampleID, targets$ExternalSampleID, targets$Description, as.character(targets$treatment))
cbind(targets$sampleID, targets$ExternalSampleID, as.character(targets$treatment))

sampleNames(rgSet) <- targets$sampleID

```

## Minfi normalization and QC filtering

Set probes to missing if detP > 0.05.

Remove probes that are bad quality (SNP overlap, cross-reactive, design problems).


```{r cache = TRUE}
#Probe and sample filtering

detP <- detectionP(rgSet)

barplot(colMeans(detP), las = 2, cex.names = 0.8, ylab = "Mean detection p-values")
abline(h = 0.05, col = "red")

qcReport(rgSet, sampNames = targets$sampleID, sampGroups = as.character(targets$treatment),
	 pdf = "minfiQCreport_v2.pdf")

#remove bad samples from rgSet
keep <- colMeans(detP) < 0.05
keep
rgSet <- rgSet[,keep]
rgSet

#remove bad samples from targets
targets <- targets[keep,]

#remove bad samples from detP matrix
detP <- detP[, keep]

#Normalization
#must load manifest to perform preprocessNoob
mSet <- preprocessNoob(rgSet)
gset <- mapToGenome(mSet)
grSet <- ratioConvert(gset, what = "both")

#After normalization, can exclude probes
# Probe exclusion based on design problems
xreact_450 <- read_xlsx("~/bigdata/EWAStools/arrayAnnotation/48639-non-specific-probes-Illumina450k.xlsx", sheet = "nonspecific cg probes")
annot_EPIC <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
table(annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID])
annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID] <- TRUE
arrayProbes <- featureNames(grSet)
annot_EPIC <- annot_EPIC[match(arrayProbes, annot_EPIC$probeID), ]
sum(arrayProbes != annot_EPIC$probeID)
grSet <- grSet[!annot_EPIC$MASK_general,]
dim(grSet)

#Probe exclusion based on detP
arrayProbes <- featureNames(grSet)
detP <- detP[match(arrayProbes, rownames(detP)), ]
# remove probes that failed in one or more samples
keep <- rowSums(detP < 0.05) == ncol(grSet)
table(keep)
grSet <- grSet[keep,]

# Data exploration with PCA and boxplots
Mvals <- getM(grSet)
boxplot(Mvals, las = 2, ylab = "M-values")

group <- targets$treatment
col.group <- group
levels(col.group) <- brewer.pal(nlevels(col.group), "Dark2")
col.group.ch <- as.character(col.group)
plotMDS(Mvals, gene.selection = "common", col = col.group.ch, pch = 16)
legend("topleft", fill = levels(col.group), legend = levels(group))

cbind(levels(group), levels(col.group))
cbind(colnames(Mvals), as.character(group), col.group.ch)

## Identify PCA outliers
myMDS <- plotMDS(Mvals, gene.selection = "common", plot = FALSE)
cluster_top <- myMDS$y[myMDS$y > 0.2 ]
cluster_bottom <- myMDS$x[myMDS$x < (-1) ]
cluster_ATV <- myMDS$x[myMDS$x > 2 ]

#cluster top
targets %>%
	filter(sampleID %in% names(cluster_top)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable

#cluster bottom
targets %>%
	filter(sampleID %in% names(cluster_bottom)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable

#cluster ATV
targets %>%
	filter(sampleID %in% names(cluster_ATV)) %>%
	dplyr::select(sampleID, SampleLabel, treatment, Description) %>%
	kable

```


## Mvals for association analysis

Using limma with Mvals

```{r cache = TRUE}

#Targets and sample IDs in same order
sum(colnames(Mvals) != targets$sampleID)
cbind(colnames(Mvals), targets$sampleID)

design <- model.matrix(~0 + treatment, data = targets)
design
colSums(design)

cm <- makeContrasts(ATVvControl = treatmentsen_ATV - treatmentnoSen_ATV,
		    SenMidasvNoSenMtnoPy = treatmentsen_noMt_noPy - treatmentnoSen_Mt_noPy,
		    SenMidasvNoSenNoMtPy = treatmentsen_noMt_noPy - treatmentnoSen_noMt_Py,
		    levels = design
		    )
fit <- lmFit(Mvals, design)
fit2 <- contrasts.fit(fit, contrasts = cm)
fit2 <- eBayes(fit2)

results <- decideTests(fit2)
summary(results)
vennDiagram(results)

volcanoplot(fit2, coef = "ATVvControl" , main = "ATV vs control")
volcanoplot(fit2, coef = "SenMidasvNoSenMtnoPy", main = "MiDAS vs control with MtDNA")
volcanoplot(fit2, coef = "SenMidasvNoSenNoMtPy", main = "MiDAS vs control without mtDNA")

topTable(fit2, coef = "ATVvControl", confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenMtnoPy", confint = TRUE) %>%
	kable()
topTable(fit2, coef = "SenMidasvNoSenNoMtPy", confint = TRUE) %>%
	kable()

resultAll <- topTable(fit2, coef = "ATVvControl", confint = TRUE, sort.by = "none", number = Inf)

write_csv(resultAll, path = "../results/limma_ATV.csv")



```




# R session 

```{r}
sessionInfo()
```
