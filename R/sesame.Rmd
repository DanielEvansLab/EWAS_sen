---
title: "EWAS senescence"
author: "Dan Evans"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

# EWAS terms

DNA methylation quantity is expressed as $\beta$ 

$$ \beta = M/(M + U)  $$

Where M = hybridization signal from a methylated version of a cytosine nucleotide and 
U =  hybridization signal from an unmethylated version of a cytosine nucleotide. 

EPIC array has type 1 and type 2 probes. Type 1 probes are from the old 27K array that uses 2 bead types per CpG. The type I probes are labeled I-green and I-red. The newer type 2 probes uses one bead type. Most of the EPIC array probes are type II.  

A detection probability represents the probability of a detected signal being background flourescence. If the probability is high, the signal is more likely to be background, and the value should be set to missing.

Standard workflows suggest to remove data points with detection P-value > 0.05.  

# Processing Illumina EPIC array with Sesame package

- EWAS array Illumina EPIC 850 

- Sesame is a [bioconductor package](https://www.bioconductor.org/packages/release/bioc/html/sesame.html)
  + Improvements on previous EWAS packages for low-level processing. 
  + Existing methods do not identify artifacts associated with detection failure. Sources of failure include: insufficient DNA due to germline or somatic deletions or hyperpolymorphism, probe cross-hybridization. 
  + Probes are masked (set to NA) with two methods: P-value with out-of-band array hybridization (pOOBAH) so that probes with detection p-value > 0.05 are masked. Probes with design issues such as overlapping SNPs are masked. Minfi uses negative control probes for background, but there are only 411 of them on the EPIC array. Sesame pOOBAH uses out-of-band (OOB) signals from type I probes in addition to negative control probes to improve background subtraction and detection calling. Minfi adopted pOOBAH, but false positive rate higher than Sesame's implementation (Fig 2 Zhou 2018, NAR).  
  + Non-linear dye bias correction. Minfi uses linear scaling. Sesame uses nonlinear scaling to better fit dye bias. 

```{r, setup}
knitr::opts_chunk$set(cache.lazy = FALSE)
```

# Sesame installation on UCR cluster

Installation of sesame and dependencies went fine, no errors or warnings.

```{r, eval = FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("sesame", lib = "~/Rlibs")
```

Installed sesameData as a dependency. 

Can check version of loaded packages with sessionInfo()

Sesame version 1.6 used.

# Load libraries
```{r}
library(tidyverse)
library(knitr)
library(sesame)
library(wheatmap)
library(multtest)
library(limma)
```

# Mask and normalize data

Sesame pipeline involves probe masking with pOOBAH, normalization with noob, and nonlinear dye bias correction.

Noob = background subtraction based on normal-exponential deconvolution using out-of-band probes.

The pipeline can be thought of as adding pOOBAH to noob. Then also the non-linear dye bias correction should be better than minfi's linear correction. 

OpenSesame takes 12 minutes, so run it once and save the output.

```{r, cache = TRUE}

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/idatFiles/")
t1 <- Sys.time()
betas <- openSesame(IDATprefixes)
Sys.time() - t1
#Warnings issued. These are also shown in minfi vignette, so they are expected. 
#50: In readChar(con, nchars = n) : truncating string with embedded nuls
#openSesame takes 12 minutes, so I'll write-out betas as a file.

#Convert Betas to Mvalues. Check if there are beta values that will result in infinite results.
sum(is.na(betas))
sum(is.na(betas))/length(betas)
sum(betas==0 & !is.na(betas))
sum(betas==1 & !is.na(betas))
sum(betas<0 & !is.na(betas))
sum(betas>1 & !is.na(betas))

Mvals <- BetaValueToMValue(betas)

#column names for betas and Mvals is currently the Basename. Rename it to sampleID to make it easier to understand.
sampsheet <- read_csv("../data/raw/idatFiles/SampleSheet.csv")
sum(colnames(betas) != sampsheet$Basename) #not in same order
cbind(colnames(betas),sampsheet$Basename) #visually show not in same order
cbind(colnames(betas),sampsheet$Basename[match(sampsheet$Basename, colnames(betas))])#now in correct order
#reorder sampsheet to match sample order in data matrix
sampsheet <- sampsheet[match(sampsheet$Basename, colnames(betas)),]
sampsheet <- rename(sampsheet, sampleID = ExternalSampleID)
cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description)
sampsheet$sampleID[1:8] <- paste0("ATV", 1:8)
sampsheet$sampleID[9:32] <- paste0("midas", 1:24) 
cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description)

translate_trt <- function(ch){
  switch(ch,
	 "Non-senescent DMSO-treated control cells" = "noSen_ATV",
	 "Non-senescent mtDNA-containing controls no pyruvate" = "noSen_Mt_noPy", 
	 "Non-senescent mtDNA-containing controls with pyruvate" = "noSen_Mt_Py",
	 "Non-senescent mtDNA-depleted controls cells with pyruvate" = "noSen_noMt_Py",
	 "Senescent ATV-treated cells" = "sen_ATV",
	 "Senescent mtDNA-depleted cells no pyruvate" = "sen_noMt_noPy"
	 )
}

sampsheet <- sampsheet %>%
	mutate(treatment = map_chr(Description, translate_trt)) %>%
	mutate(treatment = factor(treatment))

cbind(sampsheet$sampleID, sampsheet$SampleLabel, sampsheet$Description, as.character(sampsheet$treatment))

colnames(betas) <- sampsheet$sampleID
colnames(Mvals) <- sampsheet$sampleID 
row.names(sampsheet) <- sampsheet$sampleID

#Probe annotation
dat_fData <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
length(rownames(betas)) == length(dat_fData$probeID)
sum(rownames(betas) != dat_fData$probeID)
#Reorder annotation to match betas
dat_fData <- dat_fData[match(rownames(betas), dat_fData$probeID),]
sum(rownames(betas) != dat_fData$probeID)
head(dat_fData$probeID)
head(rownames(betas))
row.names(dat_fData) <- dat_fData$probeID

eset_betas <- ExpressionSet(assayData = betas,
			    phenoData = AnnotatedDataFrame(sampsheet),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

eset_Mvals <- ExpressionSet(assayData = Mvals,
			    phenoData = AnnotatedDataFrame(sampsheet),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

```

# QC on IDATs

The sesame pipeline above already produced cleaned data. This chunk goes backwards and examines QC of the raw data again.

Read in idats as sigsets, apply QC.

The Sigset data structure is an S4 class with 6 slots. Using lapply with readIDATpair creates a list of Sigset objects. Each list element is a Sigset for each sample. To plot or anything across samples, you'll need to apply a function across the list.

```{r, cache = TRUE}
sampsheet <- read_csv("../data/raw/idatFiles/SampleSheet.csv")
IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/idatFiles/")
ssets <- lapply(IDATprefixes, readIDATpair)
qc10 <- do.call(rbind, lapply(ssets, function(x)
    as.data.frame(sesameQC(x))))
#add sample names
cbind(names(ssets), sampsheet$Basename)
match(names(ssets), sampsheet$Basename)
cbind(names(ssets), sampsheet$Basename[match(names(ssets), sampsheet$Basename)], sampsheet$Basename)
qc10$sample_name <- sampsheet$ExternalSampleID[match(names(ssets), sampsheet$Basename)]
qc10$sample_desc <- sampsheet$Description[match(names(ssets), sampsheet$Basename)]

#frac_na_cg = percentage of cg probes with NA
#mean_intensity = for type II probes. Low intensity typically bad quality
#mean_beta_cg = mean beta cg probes
#frac_meth_cg = percentage cg probes with beta > 0.7
#frac_unmeth_cg = percentage cg probes with beta < 0.3
#GCT = residual incomplete bisulfite conversion. Closer to one = more complete conversion.
qcvars <- c("sample_name", "sample_desc", "num_probes_cg", "num_na_cg", "frac_na_cg", "mean_intensity", "mean_beta_cg", "frac_meth_cg", "frac_unmeth_cg", "sex", "age", "ethnicity", "GCT")
qc10 %>%
	select(any_of(qcvars)) %>%
	kable

```

# Mean intensity per sample

```{r, results = "asis"}
p1 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity), stat='identity') +
    xlab('Sample Name') + ylab('Mean Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
p2 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity_total), stat='identity') +
    xlab('Sample Name') + ylab('Mean M+U Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
WGG(p1) + WGG(p2, RightOf())


```

# Fraction of NA

The fraction of NAs are signs of masking due to variety of reasons including failed detection, high background, putative low quality probes etc. 

```{r, results = "asis"}
p1 <- ggplot(qc10) +
    geom_bar(aes(sample_name, num_na_cg), stat='identity') +
    xlab('Sample Name') + ylab('Number of NAs') +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
p2 <- ggplot(qc10) +
    geom_bar(aes(sample_name, frac_na_cg), stat='identity') +
    xlab('Sample Name') + ylab('Fraction of NAs (%)') +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
WGG(p1) + WGG(p2, RightOf())


```

# Missing analysis of masked Betas

Now we move back to the QCed betas generated from the first step. 

First, remove failed samples and probes. How many samples are missing across all probes? How many probes are missing across all samples? 

```{r, cache = TRUE}
betasDF <- read_csv("../data/formatted/betas.csv")
sampsheet <- read_csv("../data/raw/idatFiles/SampleSheet.csv")
#add sample names
cbind(names(betasDF)[2:ncol(betasDF)], sampsheet$Basename)
#Unlike last time, now want to match basename to order in betasDF to resort the sample sheet
match(sampsheet$Basename, names(betasDF[2:ncol(betasDF)]))
cbind(names(betasDF)[2:ncol(betasDF)], 
      sampsheet$Basename[match(sampsheet$Basename, names(betasDF)[2:ncol(betasDF)])],
      sampsheet$Basename
      )
#reorder sample sheet to match betasDF
sampsheet <- sampsheet[match(sampsheet$Basename, names(betasDF)[2:ncol(betasDF)]),]

#Convert betasDF to matrix for faster comp
betaMat <- betasDF %>%
	mutate(probeID = NULL) %>%
	as.matrix
	
# Add dimnames to betaMat so function outputs are named
dimnames(betaMat) <- list(betasDF$probeID, sampsheet$SampleLabel) 
miss_sample <- apply(betaMat, 2, function(x) sum(is.na(x))/length(x) )
miss_probe_blank <- apply(betaMat, 1, function(x) sum(is.na(x))/length(x) )
length(miss_sample)
length(miss_probe_blank)
sum(miss_sample >= 0.95) #0 samples have missing rate greater than 95% 
#no samples that are essentially blanks.
sum(miss_probe_blank >= 1) #119,631 completely missing probes. Many are masked by design.
sum(miss_probe_blank >= 0.95) #121,925 Remove these, then determine number of samples with missing rate>0.05.
head(sort(miss_probe_blank, decreasing = TRUE))
#keep probes with < 0.95 missingness
betaMat <- betaMat[miss_probe_blank < 0.95, ] #743,993 probes left
dim(betaMat)

#After removing failed probes, estimate sample missing rate.
miss_sample <- apply(betaMat, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(betaMat, 1, function(x) sum(is.na(x))/length(x) )
length(miss_sample)
length(miss_probe)
sort(miss_sample, decreasing = TRUE)
#verify that blank probes are removed 
sum(miss_probe >= 1) 
sum(miss_probe >= 0.95) 
head(sort(miss_probe, decreasing = TRUE))


```



# Create contrasts in sample sheet
```{r, cache = TRUE}
cbind(colnames(betaMat),
      sampsheet$SampleLabel)

#create new variables in sample sheet to indicate contrasts
#ATV contrast
samp <- sampsheet %>%
	mutate(ATV = ifelse(str_detect(SampleLabel, "\\+ ATV"), 1L, 0L))
samp$ATV[str_detect(samp$SampleLabel, ".*ATV.*", negate = TRUE)] <- NA
cbind(samp$ATV, samp$SampleLabel)
cbind(samp$SampleLabel, samp$Description)

#MiDAS contrast

cbind(samp$SampleLabel, samp$Description, str_detect(samp$SampleLabel, "mtD -P [1-9]"))
cbind(samp$SampleLabel, samp$Description, str_detect(samp$SampleLabel, "C -P [1-9]"))

samp <- sampsheet %>%
	mutate(ATV = ifelse(str_detect(SampleLabel, "mtD -P [1-9]"), 1L, 0L))
samp$ATV[str_detect(samp$SampleLabel, ".*ATV.*", negate = TRUE)] <- NA
```

# Probe-wise analysis of senescence treatment

```{r, cache = TRUE}

lm_fun <- function(cg){
  out <- tryCatch({
    lm1 <- t.test(cg ~ ATV, data = samp, na.action = na.omit)
    tstat <- lm1$statistic
    p <- lm1$p.value
    return(c(tstat, p))
  },
  error = function(e) rep(NA, 2)
  )
}

results <- apply(betaMat, 1, lm_fun)
results <- t(results)
colnames(results) <- c("T_STAT", "P")
resultsTB <- as_tibble(results)
resultsTB <- resultsTB %>%
	mutate(probeID = rownames(results)) %>%
	select(probeID, everything())
adjp1 <- mt.rawp2adjp(resultsTB[["P"]], proc = "BH")
resultsTB <- resultsTB %>%
	mutate(P_BH = adjp1$adjp[order(adjp1$index),"BH"])

write_csv(resultsTB, "../results/probewise_ATV.csv")

resultsTB %>%
	filter(P_BH <= 0.05) %>%
	count()
resultsTB %>%
	filter(P_BH <= 0.05) %>%
	kable(digits = 8)

resultsTB %>%
	arrange(P) %>%
	head() %>%
	kable(digits = 8)
```


# Probe hg19 annotation

```{r, eval = FALSE}
EPIC.hg19.manifest <- sesameDataGet("EPIC.hg19.manifest")
str(EPIC.hg19.manifest)

```

# R session 

```{r}
sessionInfo()
```
